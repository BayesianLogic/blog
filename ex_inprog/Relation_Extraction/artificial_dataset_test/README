Author: Chris Xie 2/8/14

Constructed an artifial dataset consisting of 20 sentences, and 5 relations:
	R[0] = Leadership
	R[1] = Teaches a Class
	R[2] = Student to Professor
	R[3] = Authorship
	R[4] = Made Money From

I constructed these such that there are a lot of overlaps between the argument pairs and the relations. The goal is to see if the current model has a bootstrap (or semi-supervised clustering like) effect on the data when the entities and triggers are represented ONLY as strings.


#############################

Experiment 1:

Purpose: To test bootstrapping.
 - 20 Sentences
 - 3 Relations
 - 5 Verbs, 2 for R[0], 2 for R[1], 1 for R[2]
 - Sentences 0-6 are leadership, 7-13 are teaches, 14-19 are student_of

  R[0] = Leadership
  R[1] = Teaches a Class
  R[2] = Student to Professor

Triggers:
  Leadership: is_the_president_of,
  Leadership: is_the_chancellor_of,
  Teaches a Class: teaches_a_class_in,
  Teaches a Class: teaches,
  Student Of: is_a_student_of

Comments:
 - Sometimes if two sentences with same arg pair are initialized with wrong relation (even though one of them has same trigger as observed leadership relation), they tend to stay in the wrong relation. This is problematic, but perhaps a different parameter choice of dir_alpha may help solve this.

Results:

Total number of data points: 20
Number of Correct Labels: 20
Accuracy Rate: 1.0

##############################

Smaller Experiment (#2):
 - 5 sentences
 - 2 relations
 - 3 Verbs, 2 for Leadership, 1 for Teaches

Results:

Distribution of values for Rel(SourceFact(Sent[0]))
	1.0	leadership
Distribution of values for Rel(SourceFact(Sent[1]))
	1.0	leadership
Distribution of values for Rel(SourceFact(Sent[2]))
	0.87815	leadership
	0.12185	teaches
Distribution of values for Rel(SourceFact(Sent[3]))
	1.0	teaches
Distribution of values for Rel(SourceFact(Sent[4]))
	0.88195	teaches
	0.11805	leadership

Bootstrap seems to work. 

##############################

Experiment (#3):
 - 20 sentences, medium dataset
 - 3 relations
 - NO LABELS

Results: Almost clusters consistently. Does a pretty good job, much better mixing.

Here is a sample of the distribution after 100k samples, 40k burn in samples. Dir_alpha = 0.1, making the Dirichlet Distribution very spiky. This answer is very confident.

Distribution of values for Rel(SourceFact(Sent[0]))
	0.8781333333333333	R[0]
	0.07331666666666667	R[2]
	0.04855	R[1]
Distribution of values for Rel(SourceFact(Sent[1]))
	0.8681166666666666	R[0]
	0.08008333333333334	R[2]
	0.0518	R[1]
Distribution of values for Rel(SourceFact(Sent[2]))
	0.9599833333333333	R[0]
	0.033883333333333335	R[2]
	0.0061333333333333335	R[1]
Distribution of values for Rel(SourceFact(Sent[3]))
	0.9523666666666667	R[0]
	0.03693333333333333	R[2]
	0.0107	R[1]
Distribution of values for Rel(SourceFact(Sent[4]))
	0.96015	R[0]
	0.033716666666666666	R[2]
	0.0061333333333333335	R[1]
Distribution of values for Rel(SourceFact(Sent[5]))
	0.95015	R[0]
	0.03693333333333333	R[2]
	0.012916666666666667	R[1]
Distribution of values for Rel(SourceFact(Sent[6]))
	0.8880333333333333	R[0]
	0.07948333333333334	R[2]
	0.032483333333333336	R[1]
Distribution of values for Rel(SourceFact(Sent[7]))
	0.8838333333333334	R[1]
	0.11256666666666666	R[2]
	0.0036	R[0]
Distribution of values for Rel(SourceFact(Sent[8]))
	0.8039	R[1]
	0.15693333333333334	R[2]
	0.03916666666666667	R[0]
Distribution of values for Rel(SourceFact(Sent[9]))
	0.7738333333333334	R[1]
	0.17408333333333334	R[2]
	0.052083333333333336	R[0]
Distribution of values for Rel(SourceFact(Sent[10]))
	0.7734	R[1]
	0.1755	R[2]
	0.0511	R[0]
Distribution of values for Rel(SourceFact(Sent[11]))
	0.8799166666666667	R[1]
	0.11258333333333333	R[2]
	0.0075	R[0]
Distribution of values for Rel(SourceFact(Sent[12]))
	0.8845	R[1]
	0.11205	R[2]
	0.00345	R[0]
Distribution of values for Rel(SourceFact(Sent[13]))
	0.8799166666666667	R[1]
	0.11258333333333333	R[2]
	0.0075	R[0]
Distribution of values for Rel(SourceFact(Sent[14]))
	0.7311333333333333	R[2]
	0.1635	R[0]
	0.10536666666666666	R[1]
Distribution of values for Rel(SourceFact(Sent[15]))
	0.7304166666666667	R[2]
	0.16541666666666666	R[0]
	0.10416666666666667	R[1]
Distribution of values for Rel(SourceFact(Sent[16]))
	0.72595	R[2]
	0.16805	R[0]
	0.106	R[1]
Distribution of values for Rel(SourceFact(Sent[17]))
	0.7225	R[2]
	0.17013333333333333	R[0]
	0.10736666666666667	R[1]
Distribution of values for Rel(SourceFact(Sent[18]))
	0.7082666666666667	R[2]
	0.17891666666666667	R[0]
	0.11281666666666666	R[1]
Distribution of values for Rel(SourceFact(Sent[19]))
	0.6841333333333334	R[2]
	0.18323333333333333	R[0]
	0.13263333333333333	R[1]
======== Done ========

######################################################

Experiment 4a: Trigger Disambiguation
	- 10 sentences
		- 4 sentences with "operate", 4 sentences with "sprint", 2 sentences with "run", where there is an overlap of argument pairs.
	- 2 Relations
	- 3 Verbs, 1 for R[0], 1 for R[1], and 1 that belongs to both, that needs to be disambiguated.

In the ground truth, Sentence 4 should be lumped with Sentences 0 - 3, and Sentence 5 should be lumped with Sentences 6 - 9.

Results: The corect disambiguation happens here:

Distribution of values for Rel(SourceFact(Sent[0]))
	0.5888	R[0]
	0.4112	R[1]
Distribution of values for Rel(SourceFact(Sent[1]))
	0.5644833333333333	R[0]
	0.43551666666666666	R[1]
Distribution of values for Rel(SourceFact(Sent[2]))
	0.5737333333333333	R[0]
	0.4262666666666667	R[1]
Distribution of values for Rel(SourceFact(Sent[3]))
	0.50885	R[0]
	0.49115	R[1]
Distribution of values for Rel(SourceFact(Sent[4]))
	0.5119166666666667	R[1]
	0.4880833333333333	R[0]
Distribution of values for Rel(SourceFact(Sent[5]))
	0.5952	R[1]
	0.4048	R[0]
Distribution of values for Rel(SourceFact(Sent[6]))
	0.5929666666666666	R[1]
	0.40703333333333336	R[0]
Distribution of values for Rel(SourceFact(Sent[7]))
	0.5959666666666666	R[1]
	0.40403333333333336	R[0]
Distribution of values for Rel(SourceFact(Sent[8]))
	0.59985	R[1]
	0.40015	R[0]
Distribution of values for Rel(SourceFact(Sent[9]))
	0.5997666666666667	R[1]
	0.40023333333333333	R[0]
======== Done ========

Experiment 4b:
	- 10 sentences
		- 3 sentences with "operate", 3 sentences with "sprint", 4 sentences with "run", two should go with operate, two should go with "sprint"
	- 2 Relations
	- 3 Verbs, same as Experiment 4a

In the ground truth, Sentences 0 - 4 should be lumped together, and Sentences 5 - 9 should be lumped together.

Results:

Not good, clustering everything into one relation, with very little confidence..

Distribution of values for Rel(SourceFact(Sent[0]))
	0.5256133333333334	R[0]
	0.4743866666666667	R[1]
Distribution of values for Rel(SourceFact(Sent[1]))
	0.5314433333333334	R[0]
	0.4685566666666667	R[1]
Distribution of values for Rel(SourceFact(Sent[2]))
	0.5318788888888889	R[0]
	0.4681211111111111	R[1]
Distribution of values for Rel(SourceFact(Sent[3]))
	0.5298366666666666	R[0]
	0.4701633333333333	R[1]
Distribution of values for Rel(SourceFact(Sent[4]))
	0.5304788888888889	R[0]
	0.4695211111111111	R[1]
Distribution of values for Rel(SourceFact(Sent[5]))
	0.5145933333333333	R[0]
	0.48540666666666665	R[1]
Distribution of values for Rel(SourceFact(Sent[6]))
	0.5145611111111111	R[0]
	0.48543888888888886	R[1]
Distribution of values for Rel(SourceFact(Sent[7]))
	0.5171522222222222	R[0]
	0.48284777777777776	R[1]
Distribution of values for Rel(SourceFact(Sent[8]))
	0.51814	R[0]
	0.48186	R[1]
Distribution of values for Rel(SourceFact(Sent[9]))
	0.5101166666666667	R[0]
	0.48988333333333334	R[1]
======== Done ========

Here is a trial where the clustering is correct, still with not much confidence:

Distribution of values for Rel(SourceFact(Sent[0]))
	0.54079	R[0]
	0.45921	R[1]
Distribution of values for Rel(SourceFact(Sent[1]))
	0.527655	R[0]
	0.472345	R[1]
Distribution of values for Rel(SourceFact(Sent[2]))
	0.53103	R[0]
	0.46897	R[1]
Distribution of values for Rel(SourceFact(Sent[3]))
	0.530565	R[0]
	0.469435	R[1]
Distribution of values for Rel(SourceFact(Sent[4]))
	0.528745	R[0]
	0.471255	R[1]
Distribution of values for Rel(SourceFact(Sent[5]))
	0.53461	R[1]
	0.46539	R[0]
Distribution of values for Rel(SourceFact(Sent[6]))
	0.53312	R[1]
	0.46688	R[0]
Distribution of values for Rel(SourceFact(Sent[7]))
	0.535155	R[1]
	0.464845	R[0]
Distribution of values for Rel(SourceFact(Sent[8]))
	0.53077	R[1]
	0.46923	R[0]
Distribution of values for Rel(SourceFact(Sent[9]))
	0.543125	R[1]
	0.456875	R[0]
======== Done ========


BUT!! If I label two sentences' relations, I get the right results, with good confidence:

Distribution of values for Rel(SourceFact(Sent[0]))
	1.0	R[0]
Distribution of values for Rel(SourceFact(Sent[1]))
	0.829815	R[0]
	0.170185	R[1]
Distribution of values for Rel(SourceFact(Sent[2]))
	0.83593	R[0]
	0.16407	R[1]
Distribution of values for Rel(SourceFact(Sent[3]))
	0.83557	R[0]
	0.16443	R[1]
Distribution of values for Rel(SourceFact(Sent[4]))
	0.830165	R[0]
	0.169835	R[1]
Distribution of values for Rel(SourceFact(Sent[5]))
	0.815655	R[1]
	0.184345	R[0]
Distribution of values for Rel(SourceFact(Sent[6]))
	0.82122	R[1]
	0.17878	R[0]
Distribution of values for Rel(SourceFact(Sent[7]))
	0.82334	R[1]
	0.17666	R[0]
Distribution of values for Rel(SourceFact(Sent[8]))
	0.8199	R[1]
	0.1801	R[0]
Distribution of values for Rel(SourceFact(Sent[9]))
	1.0	R[1]
======== Done ========

Hmm.. maybe not enough data? At least we know with semi-supervised clustering, it will work.
