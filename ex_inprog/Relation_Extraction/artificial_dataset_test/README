Author: Chris Xie 2/8/14

Constructed an artifial dataset consisting of 20 sentences, and 5 relations:
	R[0] = Leadership
	R[1] = Teaches a Class
	R[2] = Student to Professor
	R[3] = Authorship
	R[4] = Made Money From

I constructed these such that there are a lot of overlaps between the argument pairs and the relations. The goal is to see if the current model has a bootstrap (or semi-supervised clustering like) effect on the data when the entities and triggers are represented ONLY as strings.


#############################

Experiment 1:

Purpose: To test bootstrapping.
 - 20 Sentences
 - 3 Relations
 - 5 Verbs, 2 for R[0], 2 for R[1], 1 for R[2]
 - Sentences 0-6 are leadership, 7-13 are teaches, 14-19 are student_of

  R[0] = Leadership
  R[1] = Teaches a Class
  R[2] = Student to Professor

Triggers:
  Leadership: is_the_president_of,
  Leadership: is_the_chancellor_of,
  Teaches a Class: teaches_a_class_in,
  Teaches a Class: teaches,
  Student Of: is_a_student_of

Comments:
 - Sometimes if two sentences with same arg pair are initialized with wrong relation (even though one of them has same trigger as observed leadership relation), they tend to stay in the wrong relation. This is problematic, but perhaps a different parameter choice of dir_alpha may help solve this.

Results:

Total number of data points: 20
Number of Correct Labels: 20
Accuracy Rate: 1.0

##############################

Smaller Experiment (#2):
 - 5 sentences
 - 2 relations
 - 3 Verbs, 2 for Leadership, 1 for Teaches

Results:

Distribution of values for Rel(SourceFact(Sent[0]))
	1.0	leadership
Distribution of values for Rel(SourceFact(Sent[1]))
	1.0	leadership
Distribution of values for Rel(SourceFact(Sent[2]))
	0.87815	leadership
	0.12185	teaches
Distribution of values for Rel(SourceFact(Sent[3]))
	1.0	teaches
Distribution of values for Rel(SourceFact(Sent[4]))
	0.88195	teaches
	0.11805	leadership

Bootstrap seems to work. 
